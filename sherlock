#!/usr/bin/python3
# coding: utf-8

# Imports Python
from sys import argv
from os import system

try:
    import requests
    from bs4 import BeautifulSoup
    from urllib.request import urlopen
    from urllib.error import HTTPError
except:
    print("Deseja instalar os requisitos faltantes? [Y/n]")
    vaiInstalar = input()
    if vaiInstalar in ('Y', 'y', 's', 'S'):
        system("sudo pip3 install -r requirements.txt")
    else:
        exit()

# My imports
from parsers.Mails import Mail
from parsers.Images import Images
from parsers.Lattes import Lattes
from utils.Arguments import Getopt
from parsers.PhysicalAddr import Physical
from utils.ExtensionFiles import ExtensionsFile


def printResult(arrayList):
    if arrayList == None or arrayList == []:
        return None
    for element in arrayList:
        if element != None:
            print(element)


def physicalInfo(html):
    zipcode = Physical(html)
    print(zipcode.getAddress())


def emailInfo(html):
    emails = Mail(html)
    printResult(emails.getMails())


def academicInfo(html):
    curriculo = Lattes(html)
    print(curriculo.html)
    printResult(curriculo.getLattes())


def imagesInfo(html, url):
    images = Images(html)
    images = images.getImages(url)
    printResult(images)


url = Getopt.requiredArgs(argv, ['-s', '--site']).strip()

try:
    html = requests.get(url)
    html = html.text
except HTTPError as error:
    print('Erro de requisição para: ' + url + '.Erro: ' + error)
    exit()

# For regex search - String return
beautifulHTML = BeautifulSoup(html, 'html.parser').prettify()

# For BeautifulSoup search - encoding string return
codingHTML = BeautifulSoup(html, 'html.parser')

print("URL analisada: " + url + '\n')

emailInfo(beautifulHTML)
academicInfo(beautifulHTML)
imagesInfo(codingHTML, url)
physicalInfo(beautifulHTML)
